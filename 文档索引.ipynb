{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对文档建立索引并实现检索及排序 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Title: 对文档建立索引并实现检索及排序   \n",
    "@Author: JJYDXFS   \n",
    "@Date: 11 July 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    '''\n",
    "    读文件内容\n",
    "    '''\n",
    "    fp = open(file_path,\"r\",encoding='gbk',errors='ignore')\n",
    "    content = fp.read()\n",
    "    fp.close()\n",
    "    return content\n",
    "\n",
    "def create_stopwords(file_path):\n",
    "    '''\n",
    "    创建停词列表\n",
    "    '''\n",
    "    stopwords = [line.strip() for line in open(file_path, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "def preprocess(content):\n",
    "    '''\n",
    "    对文本文件预处理\n",
    "    '''\n",
    "    content = content.replace(\"\\n\", \"\")\n",
    "    content = content.replace(\"\\u3000\", \"\")\n",
    "    \n",
    "    # content = content.replace(\" \", \"\")\n",
    "    return content\n",
    "\n",
    "def create_seq_index(start_doc_id, end_doc_id):\n",
    "    '''\n",
    "    建立顺序索引\n",
    "    '''\n",
    "    seq_index={}\n",
    "    for doc_id in range(start_doc_id, end_doc_id, 1):\n",
    "        raw_content = read_file(corpus_path+str(doc_id)+\".txt\").strip()\n",
    "        content = preprocess(raw_content)\n",
    "        content_seg = jieba.cut(content)    # jieba分词\n",
    "        \n",
    "        word_map = {} # 定义单文档词项表\n",
    "        \n",
    "        # 去停词 + 计算出现次数\n",
    "        word_amount = 0\n",
    "        for word in content_seg:\n",
    "            word_amount+=1\n",
    "            if word not in stopwords:\n",
    "                if word not in word_map.keys():\n",
    "                    word_map[word]=1\n",
    "                else:\n",
    "                    word_map[word]+=1\n",
    "        # 计算 tf\n",
    "        for word in word_map:\n",
    "            # word_map[word]/=word_amount\n",
    "            word_map[word] = round(word_map[word]/word_amount,8)\n",
    "        # 存入顺排索引\n",
    "        seq_index[doc_id]=word_map\n",
    "        \n",
    "    return seq_index\n",
    "\n",
    "def Invert_in_batch(seq_index):\n",
    "    '''\n",
    "    对每块文档建立倒排索引\n",
    "    '''\n",
    "    \n",
    "    global word_id_map\n",
    "    global word_id_counting\n",
    "    global word_id_table\n",
    "    \n",
    "    # 由顺序索引建立倒排索引\n",
    "    tmp_word_table = {} # 定义 当前文档块 的词项表\n",
    "    pos_table = {} # 定义 当前文档块 的倒排记录表\n",
    "    for doc_id in seq_index: # 遍历顺序索引建立倒排索引\n",
    "        for word in seq_index[doc_id]:\n",
    "            if word not in word_id_map: # 全局词项表未收录词\n",
    "                word_id_map[word] =  word_id_counting # 加入全局词项表映射\n",
    "                word_id_table[word_id_map[word]] = 1 # 加入全局词项表\n",
    "                word_id_counting += 1 # 序号自增\n",
    "            \n",
    "            word_id = word_id_map[word] # 获取词项表对应序号\n",
    "            \n",
    "            if word_id not in tmp_word_table: # 局部词项表未收录词\n",
    "                tmp_word_table[word_id] = True # 加入局部词项表\n",
    "                pos_table[word_id] = {doc_id:seq_index[doc_id][word]} # 创建倒排记录\n",
    "            else:\n",
    "                word_id_table[word_id] +=1\n",
    "                pos_table[word_id][doc_id] = seq_index[doc_id][word] # 更新倒排记录\n",
    "    \n",
    "    return pos_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 预处理工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建停词列表\n",
    "stopwords_file = \"F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\cn_stopwords.txt\"\n",
    "stopwords=create_stopwords(stopwords_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立倒排索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 基于内存建立倒排索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 23.06274104118347 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\testdata\\\\' # 文本语料路径\n",
    "    corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\data\\\\Sogou\\\\' # 文本语料路径\n",
    "    start_doc_id, end_doc_id = 1, 2001 # 指定文档集范围，左闭右开\n",
    "    doc_number = end_doc_id - start_doc_id # 文档总数\n",
    "    \n",
    "    # 建立顺序索引\n",
    "    seq_index=create_seq_index(start_doc_id, end_doc_id)\n",
    "    \n",
    "    # 由顺序索引建立倒排索引\n",
    "    word_table = {} # 定义词项表\n",
    "    invert_table = {} # 定义倒排记录表\n",
    "    for doc_id in seq_index: # 遍历顺序索引建立倒排索引\n",
    "        for word in seq_index[doc_id]:\n",
    "            if word not in word_table: # 未收录词\n",
    "                word_table[word] = 1 # 加入词项表\n",
    "                invert_table[word] = {doc_id:seq_index[doc_id][word]} # 创建倒排记录\n",
    "            else:\n",
    "                word_table[word] +=1\n",
    "                invert_table[word][doc_id] = seq_index[doc_id][word]\n",
    "    \n",
    "    # 计算 idf\n",
    "    for word in word_table:\n",
    "        word_table[word] = round(word_table[word]/doc_number, 8)\n",
    "                \n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 基于外部磁盘建立倒排索引（分块处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 225.83593440055847 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\testdata\\\\' # 文本语料路径\n",
    "    corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\data\\\\Sogou\\\\' # 文本语料路径\n",
    "    output_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\output\\\\' # 输出索引文件路径\n",
    "    start_doc_id, end_doc_id = 10, 2000 # 指定文档集范围，左闭右开\n",
    "    doc_number = end_doc_id - start_doc_id # 文档总数\n",
    "    \n",
    "    batch = 10 # 指定块数\n",
    "    \n",
    "    assert (end_doc_id - start_doc_id) % batch == 0 # 保证文档总数是batch的整数倍\n",
    "    batch_size = int((end_doc_id - start_doc_id)/batch) # 分块进行处理\n",
    "    \n",
    "    # 全局变量\n",
    "    word_id_map ={} # 维护 词项及其序号映射\n",
    "    word_id_table = {} # 定义词项表\n",
    "    word_id_counting = 0 # 词项自增序号\n",
    "    \n",
    "    tmp_doc_id = start_doc_id # 指定每块起始文档\n",
    "    batch_count = 0 # 块计数器\n",
    "    \n",
    "    while batch_count != batch: # 还有块未处理完时则继续\n",
    "        # 建立顺序索引\n",
    "        seq_index = create_seq_index(tmp_doc_id, tmp_doc_id + batch_size)\n",
    "        # 建立倒排索引\n",
    "        tmp_pos_table = Invert_in_batch(seq_index)\n",
    "        # 将块的倒排索引写入磁盘\n",
    "        np.save(output_path+str(batch_count) + \".npy\", tmp_pos_table)\n",
    "        batch_count += 1\n",
    "        # 读下一块\n",
    "        tmp_doc_id += batch_size\n",
    "        \n",
    "    # 合并倒排索引\n",
    "    invert_table = np.load(output_path+\"0.npy\",allow_pickle=True)[()] # 将nd array转为内置字典\n",
    "    for table in range(1,batch):\n",
    "        invert_table_tmp = np.load(output_path + str(table) + \".npy\",allow_pickle=True)[()]\n",
    "        for word_id in invert_table_tmp:\n",
    "            if word_id in invert_table.keys(): # 若待合并项在原索引表中则更新原表项\n",
    "                invert_table[word_id].update(invert_table_tmp[word_id])\n",
    "            else: # 若待合并项不在原索引表中则新增一项\n",
    "                invert_table[word_id] = invert_table_tmp[word_id]\n",
    "    \n",
    "    # 输出合并后的完整倒排索引\n",
    "    # np.save(output_path+ \"result.npy\", invert_table)\n",
    "    \n",
    "    # 计算 idf\n",
    "    for word_id in word_id_table:\n",
    "        word_id_table[word] = round(word_id_table[word_id]/doc_number, 8)\n",
    "                \n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(invert_table_dict[word_id_map['教育']])\n",
    "#print(sorted(invert_table[word_id_map['孩子']].items(), key = lambda kv:(kv[1], kv[0])))\n",
    "#print(invert_table[word_id_map['教育']])\n",
    "#np.save(output_path+ \"result.npy\", invert_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 布尔检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(word):\n",
    "    '''\n",
    "    获得词项的倒排记录集合\n",
    "    异常处理待完善\n",
    "    '''\n",
    "    try:\n",
    "        result = set(list(invert_table[word].keys()))\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        \n",
    "    return result\n",
    "\n",
    "def get_precede(op1, op2):\n",
    "    '''\n",
    "    返回两运算符优先级关系\n",
    "    @param\n",
    "    op1: 栈顶元素\n",
    "    op2: 栈外元素\n",
    "    @return\n",
    "    优先级关系: > < = !\n",
    "    '''\n",
    "    \n",
    "    if op2 == '#': return '>'\n",
    "    \n",
    "    precede_map={\n",
    "        '(':{'(':'<', ')':'=', 'AND':'<', 'OR':'<', 'ANDNOT':'<'},\n",
    "        ')':{'(':'!', ')':'>', 'AND':'>', 'OR':'>', 'ANDNOT':'>'},\n",
    "        'AND':{'(':'<', ')':'>', 'AND':'>', 'OR':'>', 'ANDNOT':'>'},\n",
    "        'OR':{'(':'<', ')':'>', 'AND':'<', 'OR':'>', 'ANDNOT':'<'},\n",
    "        'ANDNOT':{'(':'<', ')':'>', 'AND':'>', 'OR':'>', 'ANDNOT':'>'}\n",
    "    }\n",
    "\n",
    "    return precede_map[op1][op2]\n",
    "\n",
    "def is_op(op):\n",
    "    '''\n",
    "    判断是否为运算符\n",
    "    '''\n",
    "    return (op == '(' or op == ')' or op == 'AND' or op == 'OR' or op == 'ANDNOT')\n",
    "\n",
    "def calc_record(record1, record2, op):\n",
    "    '''\n",
    "    按运算符对倒排记录执行计算\n",
    "    '''\n",
    "    if op == 'AND':\n",
    "        return record1 & record2\n",
    "    elif op == 'OR':\n",
    "        return record1 | record2\n",
    "    elif op == 'ANDNOT':\n",
    "        return record2 - record1\n",
    "    else:\n",
    "        # 非法输入\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bool_exp(exp):\n",
    "    '''\n",
    "    计算布尔表达式\n",
    "    @param \n",
    "    exp: 布尔表达式的列表形式\n",
    "    @return\n",
    "    result[-1]: 总体交集\n",
    "    word_set: 涉及的词项集合\n",
    "    '''\n",
    "    result_stack=[] # 预算结果栈\n",
    "    op_stack=[] # 运算符栈\n",
    "    word_set = set([]) # 词项集合\n",
    "    i = 0 # 计数器i\n",
    "    elen = len(exp) # 表达式长度\n",
    "\n",
    "    while i < elen or len(op_stack) != 0:\n",
    "\n",
    "        if i < elen and not is_op(exp[i]): # 词项入栈\n",
    "            result_stack.append(get_record(exp[i]))\n",
    "            word_set.add(exp[i]) # 词项入集合\n",
    "            i += 1\n",
    "        elif i<elen and len(op_stack) == 0: # 第一个运算符入栈\n",
    "            op_stack.append(exp[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            op1 = op_stack[-1] # 取运算符栈顶元素\n",
    "            # 取当前运算符，若表达式结束，则返回 '#'\n",
    "            c = exp[i] if i < elen else '#'\n",
    "            # 判断栈顶和当前运算符的优先级\n",
    "            precede = get_precede(op1, c)\n",
    "            if precede == '<':\n",
    "                op_stack.append(c)\n",
    "                i += 1\n",
    "            elif precede == '=':\n",
    "                op_stack.pop()\n",
    "                i += 1\n",
    "            elif precede == '>':\n",
    "                op_stack.pop() # 栈顶运算符出栈\n",
    "                record1 = result_stack.pop() # 中间结果1出栈\n",
    "                record2 = result_stack.pop() # 中间结果2出栈\n",
    "                result = calc_record(record1, record2, op1) \n",
    "                result_stack.append(result) # 计算结果入栈\n",
    "            else:\n",
    "                # 优先级错误\n",
    "                return\n",
    "\n",
    "    return result_stack[-1], word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试对照程序\n",
    "edu = set(list(invert_table['教育'].keys()))\n",
    "stu = set(list(invert_table['学生'].keys()))\n",
    "child = set(list(invert_table['孩子'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((stu - child) | (edu - child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入检索表达式：大学 AND 高中\n"
     ]
    }
   ],
   "source": [
    "# 测试驱动：输入表达式字符串\n",
    "# exp_str = '孩子'\n",
    "exp_str = input('请输入检索表达式：')\n",
    "exp=exp_str.split(' ')\n",
    "# 运行计算程序\n",
    "search_result, word_set = calc_bool_exp(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{741}\n"
     ]
    }
   ],
   "source": [
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'中学', '大学'}\n"
     ]
    }
   ],
   "source": [
    "print(word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 基于TF/IDF排序对检索结果进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(741, 4.7917e-06)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_result = {}\n",
    "\n",
    "for doc in search_result: # 计算每个文档的 tfidf 值\n",
    "    tfidf = 0\n",
    "    for word in word_set:\n",
    "        # 词没有对应文档倒排记录的，tf置为 0 \n",
    "        tf = 0 if doc not in invert_table[word].keys() else invert_table[word][doc]\n",
    "        idf = word_table[word]\n",
    "        tfidf += round(tf*idf, 10)\n",
    "    sorted_result[doc] = tfidf\n",
    "\n",
    "# 降序排列\n",
    "sorted(sorted_result.items(), key = lambda kv:(kv[1], kv[0]), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.056px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
