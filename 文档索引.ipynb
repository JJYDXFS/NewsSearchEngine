{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对文档建立索引并实现检索及排序 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Title: 对文档建立索引并实现检索及排序   \n",
    "@Author: JJYDXFS   \n",
    "@Date: 11 July 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    '''\n",
    "    读文件内容\n",
    "    '''\n",
    "    fp = open(file_path,\"r\",encoding='gbk',errors='ignore')\n",
    "    content = fp.read()\n",
    "    fp.close()\n",
    "    return content\n",
    "\n",
    "def create_stopwords(file_path):\n",
    "    '''\n",
    "    创建停词列表\n",
    "    '''\n",
    "    stopwords = [line.strip() for line in open(file_path, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "def preprocess(content):\n",
    "    '''\n",
    "    对文本文件预处理\n",
    "    '''\n",
    "    content = content.replace(\"\\n\", \"\")\n",
    "    content = content.replace(\"\\u3000\", \"\")\n",
    "    \n",
    "    # content = content.replace(\" \", \"\")\n",
    "    return content\n",
    "\n",
    "def create_seq_index(start_doc_id, end_doc_id):\n",
    "    '''\n",
    "    建立顺序索引\n",
    "    '''\n",
    "    seq_index={}\n",
    "    for doc_id in range(start_doc_id, end_doc_id, 1):\n",
    "        raw_content = read_file(corpus_path+str(doc_id)+\".txt\").strip()\n",
    "        content = preprocess(raw_content)\n",
    "        content_seg = jieba.cut(content)    # jieba分词\n",
    "        \n",
    "        word_map = {} # 定义单文档词项表\n",
    "        \n",
    "        # 去停词 + 计算出现次数\n",
    "        word_amount = 0\n",
    "        for word in content_seg:\n",
    "            word_amount+=1\n",
    "            if word not in stopwords:\n",
    "                if word not in word_map.keys():\n",
    "                    word_map[word]=1\n",
    "                else:\n",
    "                    word_map[word]+=1\n",
    "        # 计算 tf\n",
    "        for word in word_map:\n",
    "            # word_map[word]/=word_amount\n",
    "            word_map[word] = round(word_map[word]/word_amount,8)\n",
    "        # 存入顺排索引\n",
    "        seq_index[doc_id]=word_map\n",
    "        \n",
    "    return seq_index\n",
    "\n",
    "def Invert_in_batch(seq_index):\n",
    "    '''\n",
    "    对每块文档建立倒排索引\n",
    "    '''\n",
    "    \n",
    "    global word_id_map\n",
    "    global word_id_counting\n",
    "    global word_id_table\n",
    "    \n",
    "    # 由顺序索引建立倒排索引\n",
    "    tmp_word_table = {} # 定义 当前文档块 的词项表\n",
    "    pos_table = {} # 定义 当前文档块 的倒排记录表\n",
    "    for doc_id in seq_index: # 遍历顺序索引建立倒排索引\n",
    "        for word in seq_index[doc_id]:\n",
    "            if word not in word_id_map: # 全局词项表未收录词\n",
    "                word_id_map[word] =  word_id_counting # 加入全局词项表映射\n",
    "                word_id_table[word_id_map[word]] = 1 # 加入全局词项表\n",
    "                word_id_counting += 1 # 序号自增\n",
    "            \n",
    "            word_id = word_id_map[word] # 获取词项表对应序号\n",
    "            \n",
    "            if word_id not in tmp_word_table: # 局部词项表未收录词\n",
    "                tmp_word_table[word_id] = True # 加入局部词项表\n",
    "                pos_table[word_id] = {doc_id:seq_index[doc_id][word]} # 创建倒排记录\n",
    "            else:\n",
    "                word_id_table[word_id] +=1\n",
    "                pos_table[word_id][doc_id] = seq_index[doc_id][word] # 更新倒排记录\n",
    "    \n",
    "    return pos_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 预处理工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建停词列表\n",
    "stopwords_file = \"F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\cn_stopwords.txt\"\n",
    "stopwords=create_stopwords(stopwords_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立倒排索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 基于内存建立倒排索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\JOYCE\\AppData\\Local\\Temp\\jieba.cache\n",
      "DEBUG:jieba:Loading model from cache C:\\Users\\JOYCE\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.810 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.810 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 23.336418390274048 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\testdata\\\\' # 文本语料路径\n",
    "    corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\data\\\\Sogou\\\\' # 文本语料路径\n",
    "    start_doc_id, end_doc_id = 1, 2001 # 指定文档集范围，左闭右开\n",
    "    doc_number = end_doc_id - start_doc_id # 文档总数\n",
    "    \n",
    "    # 建立顺序索引\n",
    "    seq_index=create_seq_index(start_doc_id, end_doc_id)\n",
    "    \n",
    "    # 由顺序索引建立倒排索引\n",
    "    word_table = {} # 定义词项表\n",
    "    invert_table = {} # 定义倒排记录表\n",
    "    for doc_id in seq_index: # 遍历顺序索引建立倒排索引\n",
    "        for word in seq_index[doc_id]:\n",
    "            if word not in word_table: # 未收录词\n",
    "                word_table[word] = 1 # 加入词项表\n",
    "                invert_table[word] = {doc_id:seq_index[doc_id][word]} # 创建倒排记录\n",
    "            else:\n",
    "                word_table[word] +=1\n",
    "                invert_table[word][doc_id] = seq_index[doc_id][word]\n",
    "    \n",
    "    # 计算 idf\n",
    "    for word in word_table:\n",
    "        word_table[word] = round(word_table[word]/doc_number, 8)\n",
    "                \n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 基于外部磁盘建立倒排索引（分块处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 225.83593440055847 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\testdata\\\\' # 文本语料路径\n",
    "    corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\data\\\\Sogou\\\\' # 文本语料路径\n",
    "    output_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\output\\\\' # 输出索引文件路径\n",
    "    start_doc_id, end_doc_id = 10, 2000 # 指定文档集范围，左闭右开\n",
    "    doc_number = end_doc_id - start_doc_id # 文档总数\n",
    "    \n",
    "    batch = 10 # 指定块数\n",
    "    \n",
    "    assert (end_doc_id - start_doc_id) % batch == 0 # 保证文档总数是batch的整数倍\n",
    "    batch_size = int((end_doc_id - start_doc_id)/batch) # 分块进行处理\n",
    "    \n",
    "    # 全局变量\n",
    "    word_id_map ={} # 维护 词项及其序号映射\n",
    "    word_id_table = {} # 定义词项表\n",
    "    word_id_counting = 0 # 词项自增序号\n",
    "    \n",
    "    tmp_doc_id = start_doc_id # 指定每块起始文档\n",
    "    batch_count = 0 # 块计数器\n",
    "    \n",
    "    while batch_count != batch: # 还有块未处理完时则继续\n",
    "        # 建立顺序索引\n",
    "        seq_index = create_seq_index(tmp_doc_id, tmp_doc_id + batch_size)\n",
    "        # 建立倒排索引\n",
    "        tmp_pos_table = Invert_in_batch(seq_index)\n",
    "        # 将块的倒排索引写入磁盘\n",
    "        np.save(output_path+str(batch_count) + \".npy\", tmp_pos_table)\n",
    "        batch_count += 1\n",
    "        # 读下一块\n",
    "        tmp_doc_id += batch_size\n",
    "        \n",
    "    # 合并倒排索引\n",
    "    invert_table = np.load(output_path+\"0.npy\",allow_pickle=True)[()] # 将nd array转为内置字典\n",
    "    for table in range(1,batch):\n",
    "        invert_table_tmp = np.load(output_path + str(table) + \".npy\",allow_pickle=True)[()]\n",
    "        for word_id in invert_table_tmp:\n",
    "            if word_id in invert_table.keys(): # 若待合并项在原索引表中则更新原表项\n",
    "                invert_table[word_id].update(invert_table_tmp[word_id])\n",
    "            else: # 若待合并项不在原索引表中则新增一项\n",
    "                invert_table[word_id] = invert_table_tmp[word_id]\n",
    "    \n",
    "    # 输出合并后的完整倒排索引\n",
    "    # np.save(output_path+ \"result.npy\", invert_table)\n",
    "    \n",
    "    # 计算 idf\n",
    "    for word_id in word_id_table:\n",
    "        word_id_table[word] = round(word_id_table[word_id]/doc_number, 8)\n",
    "                \n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(invert_table_dict[word_id_map['教育']])\n",
    "#print(sorted(invert_table[word_id_map['孩子']].items(), key = lambda kv:(kv[1], kv[0])))\n",
    "#print(invert_table[word_id_map['教育']])\n",
    "#np.save(output_path+ \"result.npy\", invert_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 布尔检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(word):\n",
    "    '''\n",
    "    获得词项的倒排记录集合\n",
    "    异常处理待完善\n",
    "    '''\n",
    "    try:\n",
    "        result = set(list(invert_table[word].keys()))\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        \n",
    "    return result\n",
    "\n",
    "def get_precede(op1, op2):\n",
    "    '''\n",
    "    返回两运算符优先级关系\n",
    "    @param\n",
    "    op1: 栈顶元素\n",
    "    op2: 栈外元素\n",
    "    @return\n",
    "    优先级关系: > < = !\n",
    "    '''\n",
    "    \n",
    "    if op2 == '#': return '>'\n",
    "    \n",
    "    precede_map={\n",
    "        '(':{'(':'<', ')':'=', 'AND':'<', 'OR':'<', 'ANDNOT':'<'},\n",
    "        ')':{'(':'!', ')':'>', 'AND':'>', 'OR':'>', 'ANDNOT':'>'},\n",
    "        'AND':{'(':'<', ')':'>', 'AND':'>', 'OR':'>', 'ANDNOT':'>'},\n",
    "        'OR':{'(':'<', ')':'>', 'AND':'<', 'OR':'>', 'ANDNOT':'<'},\n",
    "        'ANDNOT':{'(':'<', ')':'>', 'AND':'>', 'OR':'>', 'ANDNOT':'>'}\n",
    "    }\n",
    "\n",
    "    return precede_map[op1][op2]\n",
    "\n",
    "def is_op(op):\n",
    "    '''\n",
    "    判断是否为运算符\n",
    "    '''\n",
    "    return (op == '(' or op == ')' or op == 'AND' or op == 'OR' or op == 'ANDNOT')\n",
    "\n",
    "def calc_record(record1, record2, op):\n",
    "    '''\n",
    "    按运算符对倒排记录执行计算\n",
    "    '''\n",
    "    if op == 'AND':\n",
    "        return record1 & record2\n",
    "    elif op == 'OR':\n",
    "        return record1 | record2\n",
    "    elif op == 'ANDNOT':\n",
    "        return record2 - record1\n",
    "    else:\n",
    "        # 非法输入\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bool_exp(exp):\n",
    "    '''\n",
    "    计算布尔表达式\n",
    "    @param \n",
    "    exp: 布尔表达式的列表形式\n",
    "    @return\n",
    "    result[-1]: 总体交集\n",
    "    word_set: 涉及的词项集合\n",
    "    '''\n",
    "    result_stack=[] # 预算结果栈\n",
    "    op_stack=[] # 运算符栈\n",
    "    word_set = set([]) # 词项集合\n",
    "    i = 0 # 计数器i\n",
    "    elen = len(exp) # 表达式长度\n",
    "\n",
    "    while i < elen or len(op_stack) != 0:\n",
    "\n",
    "        if i < elen and not is_op(exp[i]): # 词项入栈\n",
    "            result_stack.append(get_record(exp[i]))\n",
    "            word_set.add(exp[i]) # 词项入集合\n",
    "            i += 1\n",
    "        elif i<elen and len(op_stack) == 0: # 第一个运算符入栈\n",
    "            op_stack.append(exp[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            op1 = op_stack[-1] # 取运算符栈顶元素\n",
    "            # 取当前运算符，若表达式结束，则返回 '#'\n",
    "            c = exp[i] if i < elen else '#'\n",
    "            # 判断栈顶和当前运算符的优先级\n",
    "            precede = get_precede(op1, c)\n",
    "            if precede == '<':\n",
    "                op_stack.append(c)\n",
    "                i += 1\n",
    "            elif precede == '=':\n",
    "                op_stack.pop()\n",
    "                i += 1\n",
    "            elif precede == '>':\n",
    "                op_stack.pop() # 栈顶运算符出栈\n",
    "                record1 = result_stack.pop() # 中间结果1出栈\n",
    "                record2 = result_stack.pop() # 中间结果2出栈\n",
    "                result = calc_record(record1, record2, op1) \n",
    "                result_stack.append(result) # 计算结果入栈\n",
    "            else:\n",
    "                # 优先级错误\n",
    "                return\n",
    "\n",
    "    return result_stack[-1], word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试对照程序\n",
    "edu = set(list(invert_table['教育'].keys()))\n",
    "stu = set(list(invert_table['学生'].keys()))\n",
    "child = set(list(invert_table['孩子'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{45: 0.00060938, 57: 0.00065445, 65: 0.00134409, 94: 0.00120627, 95: 0.01577287, 101: 0.00282943, 124: 0.00332226, 129: 0.01470588, 209: 0.00098765, 228: 0.00043403, 234: 0.00058514, 486: 0.00167785, 534: 0.00410959, 564: 6.389e-05, 630: 0.00757576, 736: 0.00157233, 745: 0.00136612, 752: 0.00059737, 774: 0.00055741, 816: 0.00352113, 841: 0.00060901, 859: 0.00257732, 860: 0.00296736, 888: 0.00441501, 917: 0.004662, 1227: 0.00266667, 1241: 0.00409836, 1358: 4.241e-05, 1469: 0.00091241, 1531: 0.00088496, 1567: 0.00093721, 1625: 0.00396825, 1652: 0.00063816, 1673: 0.00070621, 1677: 0.00158479, 1726: 0.00059102, 1757: 0.00108932, 1776: 0.00062696, 1856: 0.00359712, 1876: 0.00114416, 1969: 0.00483092}\n"
     ]
    }
   ],
   "source": [
    "print(invert_table['教育'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((stu - child) | (edu - child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入检索表达式：北京 AND 企业\n"
     ]
    }
   ],
   "source": [
    "# 测试驱动：输入表达式字符串\n",
    "# exp_str = '孩子'\n",
    "exp_str = input('请输入检索表达式：')\n",
    "exp=exp_str.split(' ')\n",
    "# 运行计算程序\n",
    "search_result, word_set = calc_bool_exp(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7, 1040, 17, 1043, 1044, 21, 1046, 1047, 536, 1048, 1049, 1050, 1051, 541, 1053, 1054, 1056, 546, 553, 1065, 555, 1067, 45, 1068, 1069, 564, 565, 566, 1588, 1591, 74, 1099, 1101, 1615, 80, 1104, 83, 1623, 90, 94, 95, 101, 1640, 115, 1652, 1154, 1668, 133, 1672, 1677, 1684, 1191, 1201, 1203, 1718, 1211, 188, 1730, 714, 1738, 1228, 1230, 1751, 1755, 231, 1768, 1259, 1776, 753, 1268, 1269, 770, 1290, 1291, 1293, 1808, 1819, 285, 1828, 810, 1835, 1836, 1840, 1329, 309, 1853, 831, 832, 1347, 839, 840, 1866, 339, 1373, 1384, 882, 884, 391, 906, 916, 918, 1455, 1976, 955, 957, 479, 487, 1517}\n"
     ]
    }
   ],
   "source": [
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'北京', '企业'}\n"
     ]
    }
   ],
   "source": [
    "print(word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 基于TF/IDF排序对检索结果进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(840, 0.010137323299999999),\n",
       " (882, 0.009528383999999999),\n",
       " (309, 0.009528383999999999),\n",
       " (479, 0.008985073699999999),\n",
       " (918, 0.0079369735),\n",
       " (1677, 0.0065237731),\n",
       " (45, 0.005826629),\n",
       " (810, 0.0058165882),\n",
       " (1268, 0.005719511300000001),\n",
       " (80, 0.0053162696),\n",
       " (1976, 0.005103905),\n",
       " (1623, 0.0046229836),\n",
       " (1384, 0.0041428552),\n",
       " (884, 0.00401729),\n",
       " (916, 0.0040020754),\n",
       " (285, 0.0039490093),\n",
       " (1672, 0.003940246200000001),\n",
       " (1853, 0.003939862),\n",
       " (536, 0.0038124299),\n",
       " (1768, 0.0037738892),\n",
       " (17, 0.0033751975),\n",
       " (95, 0.0032492103000000003),\n",
       " (1828, 0.0030818182),\n",
       " (1684, 0.0030108006),\n",
       " (839, 0.0027259411),\n",
       " (94, 0.0026005218),\n",
       " (714, 0.0024463999),\n",
       " (1373, 0.0024260204),\n",
       " (101, 0.002250808),\n",
       " (906, 0.0019665522),\n",
       " (133, 0.0018590383),\n",
       " (1228, 0.0018456083),\n",
       " (1230, 0.0018403963),\n",
       " (1099, 0.0018152969),\n",
       " (1259, 0.0017940805000000002),\n",
       " (115, 0.0017681380999999999),\n",
       " (83, 0.0017565233),\n",
       " (1154, 0.0017339074),\n",
       " (566, 0.0016666652),\n",
       " (1776, 0.0016498427000000001),\n",
       " (90, 0.0016480000000000002),\n",
       " (1517, 0.0015923624),\n",
       " (231, 0.0015634778),\n",
       " (546, 0.0015160197000000002),\n",
       " (1056, 0.0014256018000000001),\n",
       " (1054, 0.0014256018000000001),\n",
       " (1053, 0.0014256018000000001),\n",
       " (1051, 0.0014256018000000001),\n",
       " (1050, 0.0014256018000000001),\n",
       " (1049, 0.0014256018000000001),\n",
       " (1048, 0.0014256018000000001),\n",
       " (1047, 0.0014256018000000001),\n",
       " (1046, 0.0014256018000000001),\n",
       " (1044, 0.0014256018000000001),\n",
       " (1043, 0.0014256018000000001),\n",
       " (1040, 0.0014256018000000001),\n",
       " (1291, 0.0014160777000000002),\n",
       " (1290, 0.0014160777000000002),\n",
       " (1840, 0.0013976000000000001),\n",
       " (1738, 0.0013010124),\n",
       " (753, 0.0012168682),\n",
       " (1455, 0.0012144281),\n",
       " (1203, 0.001176219),\n",
       " (1104, 0.001100367),\n",
       " (1101, 0.001100367),\n",
       " (555, 0.0010631583),\n",
       " (1269, 0.001045542),\n",
       " (832, 0.0010358964999999999),\n",
       " (1211, 0.0010344947),\n",
       " (541, 0.0010267522),\n",
       " (21, 0.0009991080999999999),\n",
       " (1718, 0.0009730896000000001),\n",
       " (1591, 0.0009439258),\n",
       " (1588, 0.0009439258),\n",
       " (831, 0.0009223764000000001),\n",
       " (339, 0.0009088868999999999),\n",
       " (1201, 0.0009016904),\n",
       " (1808, 0.000845006),\n",
       " (1835, 0.000807211),\n",
       " (1347, 0.0006769794),\n",
       " (1191, 0.00065864),\n",
       " (188, 0.0006567536),\n",
       " (391, 0.0006398567),\n",
       " (1329, 0.0006031252),\n",
       " (770, 0.0005932457),\n",
       " (1730, 0.0005808558),\n",
       " (957, 0.000575498),\n",
       " (955, 0.000575498),\n",
       " (1615, 0.0005604726),\n",
       " (1640, 0.0005390248),\n",
       " (1652, 0.0005156333),\n",
       " (7, 0.0004955892999999999),\n",
       " (1668, 0.0004498405),\n",
       " (1293, 0.0004498405),\n",
       " (1751, 0.00043302820000000003),\n",
       " (1065, 0.00039337879999999995),\n",
       " (1069, 0.0003926152),\n",
       " (1068, 0.0003926152),\n",
       " (1067, 0.0003926152),\n",
       " (74, 0.0003136542),\n",
       " (487, 0.0002746433),\n",
       " (1755, 0.0001740116),\n",
       " (564, 0.0001674134),\n",
       " (1836, 0.0001642947),\n",
       " (553, 0.0001445912),\n",
       " (1866, 0.00014369789999999998),\n",
       " (565, 0.0001254221),\n",
       " (1819, 4.39973e-05)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_result = {}\n",
    "\n",
    "for doc in search_result: # 计算每个文档的 tfidf 值\n",
    "    tfidf = 0\n",
    "    for word in word_set:\n",
    "        # 词没有对应文档倒排记录的，tf置为 0 \n",
    "        tf = 0 if doc not in invert_table[word].keys() else invert_table[word][doc]\n",
    "        idf = word_table[word]\n",
    "        tfidf += round(tf*idf, 10)\n",
    "    sorted_result[doc] = tfidf\n",
    "\n",
    "# 降序排列\n",
    "sorted(sorted_result.items(), key = lambda kv:(kv[1], kv[0]), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1984, 1992, 1998, 1943, 243, 1940, 788, 1941, 951, 1942, 348)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tuple(search_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{243, 348, 788, 951, 1940, 1941, 1942, 1943, 1984, 1992, 1998}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将摘要内容存入数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "class MySQLDB:\n",
    "    def __new__(cls, host, user, password, database):\n",
    "        \"\"\" test connection \"\"\"\n",
    "        try:\n",
    "            connect = pymysql.connect(host = host,\n",
    "                            user = user,\n",
    "                            password = password,\n",
    "                            database = database,\n",
    "                            charset = 'utf8')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Failed to connect database: \", e)\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            connect.close()\n",
    "            return super().__new__(cls)\n",
    "\n",
    "    def __init__(self, host, user, password, database):\n",
    "        \"\"\" initialize args \"\"\"\n",
    "        self.host, self.user, self.password, self.database = host, user, password, database\n",
    "\n",
    "    def query(self,sqls):\n",
    "        \"\"\" execute the sqls \"\"\"\n",
    "        assert isinstance(sqls,list), 'sqls must be a list'\n",
    "        connect = pymysql.connect(host = self.host,\n",
    "                            user = self.user,\n",
    "                            password = self.password,\n",
    "                            database = self.database,\n",
    "                            cursorclass = pymysql.cursors.DictCursor)\n",
    "        cursor = connect.cursor()\n",
    "        try:\n",
    "            for sql in sqls:\n",
    "                cursor.execute(sql)\n",
    "\n",
    "            data = cursor.fetchall()\n",
    "        except Exception as e:\n",
    "            print(\"Failed to query: \", e)\n",
    "            data = None\n",
    "        finally:\n",
    "            connect.close()\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_mysql = MySQLDB(host='localhost',\n",
    "                user='root',\n",
    "                password='618618',\n",
    "                database='test')\n",
    "\n",
    "# print(db_mysql.query([sql]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = 'F:\\\\OneDrive\\\\Documents\\\\ThirdYear\\\\MediaDataAnalysis\\\\SearchEngine\\\\data\\\\Sogou\\\\' # 文本语料路径\n",
    "doc_abstract = []\n",
    "for doc_id in range(1, 17901, 1):\n",
    "    raw_content = read_file(corpus_path+str(doc_id)+\".txt\").strip()\n",
    "    content = preprocess(raw_content)\n",
    "    doc_abstract.append(content[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成前端所需检索结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(doc):\n",
    "    server_path = \"http://localhost:5000/news={}\".format(doc)\n",
    "    return server_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "select * from detail\n",
    "where doc_id in {search_set}\n",
    "\"\"\".format(search_set = tuple(search_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlist = db_mysql.query([sql])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_detail = {}\n",
    "for item in rlist:\n",
    "    doc_detail[item['doc_id']] = item['detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成前端所需要的形式\n",
    "result_data=[]\n",
    "for doc in search_result:\n",
    "    result_data.append([\"文档\"+str(doc),get_url(doc), doc_detail[doc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['文档7',\n",
       "  'http://localhost:5000/news=7',\n",
       "  '本报记者王珍发自广州河北沧州献县的家电经销商王凤恩，2005年年中将自己的小店改为“幸福树电器连锁店”。“大卖场步步紧逼，员工素质低，信息闭'],\n",
       " ['文档1040',\n",
       "  'http://localhost:5000/news=1040',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档17',\n",
       "  'http://localhost:5000/news=17',\n",
       "  '本报记者边长勇发自北京谈论起董事会话题，ColinB.Carter滔滔不绝，作为波士顿咨询的公司治理议题资深专家，ColinB.Carter'],\n",
       " ['文档1043',\n",
       "  'http://localhost:5000/news=1043',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1044',\n",
       "  'http://localhost:5000/news=1044',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档21',\n",
       "  'http://localhost:5000/news=21',\n",
       "  '继上月永乐与大中两巨头宣布开始为期一年的合并计划后，又一个行业并购案也处于进行之中。昨天记者获悉，全球最大家电连锁巨头美国百思买将以1.2亿'],\n",
       " ['文档1046',\n",
       "  'http://localhost:5000/news=1046',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1047',\n",
       "  'http://localhost:5000/news=1047',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档536',\n",
       "  'http://localhost:5000/news=536',\n",
       "  '乳品企业三缄其口本报记者郭艾琳发自上海在乳品企业中闹得沸沸扬扬的牛奶“禁鲜令”注定不得安宁，先由去年10月1日推迟到今年6月1日实行,而今,'],\n",
       " ['文档1048',\n",
       "  'http://localhost:5000/news=1048',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1049',\n",
       "  'http://localhost:5000/news=1049',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1050',\n",
       "  'http://localhost:5000/news=1050',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1051',\n",
       "  'http://localhost:5000/news=1051',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档541',\n",
       "  'http://localhost:5000/news=541',\n",
       "  '本报记者万里江发自上海一个冷门。在中国最大的食品企业双汇集团（下称“双汇”）股权拍卖案硝烟散尽之后，人们惊讶地发现，原本夺标呼声最小的高盛及'],\n",
       " ['文档1053',\n",
       "  'http://localhost:5000/news=1053',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1054',\n",
       "  'http://localhost:5000/news=1054',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档1056',\n",
       "  'http://localhost:5000/news=1056',\n",
       "  'G捷利(行情,论坛)(000996)：中国物流领域的黑马连续的拉升和成交天量，个股的大面积崛起，正在逐步印证着牛市已经扑面而来，追逐强势品种'],\n",
       " ['文档546',\n",
       "  'http://localhost:5000/news=546',\n",
       "  '信报讯（记者周光军）继从一汽－大众单独剥离出来成立奥迪事业部后，国产奥迪再度向单干迈出实质性步伐。昨天记者从北京一家经销商处看到，每辆国产奥'],\n",
       " ['文档553',\n",
       "  'http://localhost:5000/news=553',\n",
       "  '目  录    1   重要提示    2   公司基本情况    3   会计数据和业务数据摘要    4   股本变动及股东情况    '],\n",
       " ['文档1065',\n",
       "  'http://localhost:5000/news=1065',\n",
       "  '万联证券股海掘金——风生水起G昆药(行情,论坛)（600422）： 股权之争 市场新动力短期利多因素：1. 国务院领导就稳定证券市场专门组织'],\n",
       " ['文档555',\n",
       "  'http://localhost:5000/news=555',\n",
       "  '晨报讯（记者 张黎明）“要格外警惕国际资本投机我国房地产业”，掌握着权威经济数据的研究机构—国家信息中心昨天对外资进入中国楼市的现状明确提出'],\n",
       " ['文档1067',\n",
       "  'http://localhost:5000/news=1067',\n",
       "  '万联证券股海掘金——风生水起G昆药(行情,论坛)（600422）： 股权之争  市场新动力短期利多因素：1.\\t国务院领导就稳定证券市场专门组'],\n",
       " ['文档45',\n",
       "  'http://localhost:5000/news=45',\n",
       "  '经济学家梁小民谈新型工业化中的技术突破本报记者赵杰发自北京63岁的梁小民语速总是很快，言谈间的词汇中除了经济，还有哲学、历史、古今中外典故等'],\n",
       " ['文档1068',\n",
       "  'http://localhost:5000/news=1068',\n",
       "  '万联证券股海掘金——风生水起G昆药(行情,论坛)（600422）： 股权之争  市场新动力短期利多因素：1.\\t国务院领导就稳定证券市场专门组'],\n",
       " ['文档1069',\n",
       "  'http://localhost:5000/news=1069',\n",
       "  '万联证券股海掘金——风生水起G昆药(行情,论坛)（600422）： 股权之争  市场新动力短期利多因素：1.\\t国务院领导就稳定证券市场专门组'],\n",
       " ['文档564',\n",
       "  'http://localhost:5000/news=564',\n",
       "  '&nbsp&nbsp&nbsp&nbsp●(600309)国元证券有限责任公司公布关于创设烟台万华认沽权证的公告&nbsp&nbsp&nbs'],\n",
       " ['文档565',\n",
       "  'http://localhost:5000/news=565',\n",
       "  '&nbsp&nbsp&nbsp&nbsp●(000002、200002)Ｇ万科Ａ:遗失声明&nbsp&nbsp&nbsp&nbsp李凤林不慎'],\n",
       " ['文档566',\n",
       "  'http://localhost:5000/news=566',\n",
       "  '中国移动北京地区的新资费套餐将正式推出的消息，成为5月9日多家媒体最打眼的新闻。有关方面发布消息称，这是北京最大规模、最大幅度的资费变革，手'],\n",
       " ['文档1588',\n",
       "  'http://localhost:5000/news=1588',\n",
       "  '多头能量聚集，大盘保持强势：今天沪深股市延续昨天强势上升的惯性，跳高开盘，沪指在上摸至1509点便受到抛盘打压，出现回落。从涨幅排前的个股情'],\n",
       " ['文档1591',\n",
       "  'http://localhost:5000/news=1591',\n",
       "  '多头能量聚集，大盘保持强势：今天沪深股市延续昨天强势上升的惯性，跳高开盘，沪指在上摸至1509点便受到抛盘打压，出现回落。从涨幅排前的个股情'],\n",
       " ['文档74',\n",
       "  'http://localhost:5000/news=74',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司及董事会全体成员保证信息披露的内容真实、准确、完整，没有虚假记载、误导性陈述或者重大遗漏。&n'],\n",
       " ['文档1099',\n",
       "  'http://localhost:5000/news=1099',\n",
       "  '今年“五一”楼市特别旺，一股外来购买力量不可忽视新快报记者李琳文/图最近网络上流传着一篇关于“上海白领来广州买房买得超爽”的文章，与上海、北'],\n",
       " ['文档1101',\n",
       "  'http://localhost:5000/news=1101',\n",
       "  '【首证个股】                           2006年5月9日 G特变(行情,论坛)：太阳能龙头 再现“G航天(行情,'],\n",
       " ['文档1615',\n",
       "  'http://localhost:5000/news=1615',\n",
       "  '本报记者 刘 臻 华观发重庆、北京报道已过“4·29”年报大限，*ST 族公司不得不再次面临“生死抉择”。不过这一次，或许是因为有股权分置改'],\n",
       " ['文档80',\n",
       "  'http://localhost:5000/news=80',\n",
       "  '中新网5月10日电 据京华时报报道，在信息产业部宣布批复同意北京移动大幅降低手机资费后，北京移动9日正式发布消息称，将从5月11日起陆续推出'],\n",
       " ['文档1104',\n",
       "  'http://localhost:5000/news=1104',\n",
       "  '【首证个股】                           2006年5月9日 G特变(行情,论坛)：太阳能龙头 再现“G航天(行情,'],\n",
       " ['文档83',\n",
       "  'http://localhost:5000/news=83',\n",
       "  '&nbsp&nbsp&nbsp&nbsp新华百货(行情,论坛)(600785)旗下的知名商场———银川新华百货(行情,论坛)老大楼有限公司五'],\n",
       " ['文档1623',\n",
       "  'http://localhost:5000/news=1623',\n",
       "  '&nbsp&nbsp&nbsp&nbsp据《全国医药统计网》统计，国内目前已有近300家制药企业投巨资进行GMP改造，平均每家投入2000万'],\n",
       " ['文档90',\n",
       "  'http://localhost:5000/news=90',\n",
       "  '每年的５月１７日，总会有人期待电信业新闻。因为这一天是“世界电信日”。依据以往经验，国内电信企业总要在这时有所动作。令人意外的是，今年的新闻'],\n",
       " ['文档94',\n",
       "  'http://localhost:5000/news=94',\n",
       "  '&nbsp&nbsp&nbsp&nbsp上市公司名称：北京城乡贸易中心股份有限公司&nbsp&nbsp&nbsp&nbsp股票上市地点：上海'],\n",
       " ['文档95',\n",
       "  'http://localhost:5000/news=95',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司第二大股东北京北航天华科技有限责任公司原持有公司2422万股份,占公司总股本的5.97%,现协'],\n",
       " ['文档101',\n",
       "  'http://localhost:5000/news=101',\n",
       "  '&nbsp&nbsp&nbsp&nbsp上市公司名称：北京城乡贸易中心股份有限公司&nbsp&nbsp&nbsp&nbsp股票上市地点：上海'],\n",
       " ['文档1640',\n",
       "  'http://localhost:5000/news=1640',\n",
       "  '央行牵头规划金融\"十一五\"，\"一行三会\" 分业监管现状待变“因为迷茫、无知而导致的畏惧心理逐渐褪去，中国金融业正在积累信心、方法和经验，也在'],\n",
       " ['文档115',\n",
       "  'http://localhost:5000/news=115',\n",
       "  '&nbsp&nbsp&nbsp&nbsp张家口风电建设进入高速发展的新阶段。目前，全市已开工建设的风电项目4个，风电装机容量15.9万千瓦，'],\n",
       " ['文档1652',\n",
       "  'http://localhost:5000/news=1652',\n",
       "  '&nbsp&nbsp&nbsp&nbsp目前44家信托公司披露了2005年年报。根据记者对这些年报的统计,信托业去年的盈利状况继续好转,超过'],\n",
       " ['文档1154',\n",
       "  'http://localhost:5000/news=1154',\n",
       "  '&nbsp&nbsp&nbsp&nbsp日前,在农垦总局举办的\"2006北京 北大荒绿色特色产品展销会\"上,G北大荒(行情,论坛)(6005'],\n",
       " ['文档1668',\n",
       "  'http://localhost:5000/news=1668',\n",
       "  '目前，从北京、深圳、广州及上海等地的房地产市场来看，一方面，房价快速上涨，另一方面，各地又有大量的空置楼盘没有出售。特别是一些大城市更是如此'],\n",
       " ['文档133',\n",
       "  'http://localhost:5000/news=133',\n",
       "  '&nbsp&nbsp&nbsp&nbsp周一保监会批准生命人寿修改公司章程,显示股东结构发生重大变化。但公司内部人士称公司生命人寿实际的股权'],\n",
       " ['文档1672',\n",
       "  'http://localhost:5000/news=1672',\n",
       "  '五月八日，中国信息产业部宣布北京手机资费下调，北京移动同时发布几项新的套餐业务。与过去零星的套餐相比，这次降价幅度显然较大，被叫电话资费下降'],\n",
       " ['文档1677',\n",
       "  'http://localhost:5000/news=1677',\n",
       "  '本报讯 （记者 杨文利）科技部政策法规与体制改革司副司长胡志坚日前透露，针对《国家中长期科学技术发展规划纲要（２００６－２０２０年）》配套政'],\n",
       " ['文档1684',\n",
       "  'http://localhost:5000/news=1684',\n",
       "  '近日，由“中国石油业国际产业投资联盟”倡导和推动的“股权换油源计划”在印度尼西亚、中东地区获得了6个石油区块，总价值达4亿多美元。记者了解到'],\n",
       " ['文档1191',\n",
       "  'http://localhost:5000/news=1191',\n",
       "  '&nbsp&nbsp&nbsp&nbsp吉林华微电子(行情,论坛)股份有限公司董事长夏增文先生路演致词&nbsp&nbsp&nbsp&nbs'],\n",
       " ['文档1201',\n",
       "  'http://localhost:5000/news=1201',\n",
       "  '中国农村正面临前所未有的发展机遇。取消长达2600年之久的农业税、加大对农业和农民的直接贴补、建设“绿色通道”和深化农村改革等一系列措施，无'],\n",
       " ['文档1203',\n",
       "  'http://localhost:5000/news=1203',\n",
       "  '中新网5月9日电 据《中国经济时报》报道，房价经过“五一”前后一番铺天盖地的“口水战”之后，显然并没有理会来自各方面的压力与质疑，仍然在按照'],\n",
       " ['文档1718',\n",
       "  'http://localhost:5000/news=1718',\n",
       "  '&nbsp&nbsp&nbsp&nbsp双汇发展(行情,论坛)、黄河旋风、天方药业、中孚实业及华兰生物(行情,论坛)股东背景中出现外资身影 '],\n",
       " ['文档1211',\n",
       "  'http://localhost:5000/news=1211',\n",
       "  '&nbsp&nbsp&nbsp&nbsp两面针(行情,论坛)(600249)作为国内牙膏行业民族品牌的领袖与龙头企业,在竞争激烈尤其是外资、'],\n",
       " ['文档188',\n",
       "  'http://localhost:5000/news=188',\n",
       "  '本报讯 五一长假刚过，人民币汇率便走出了快速升值行情。昨天，美元兑人民币汇率中间价以8.0090元亮相，人民币汇率比节前最后一个交易日大涨7'],\n",
       " ['文档1730',\n",
       "  'http://localhost:5000/news=1730',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司及董事会全体成员保证信息披露内容的真实、准确、完整，没有虚假记载、误导性陈述或重大遗漏。&nb'],\n",
       " ['文档714',\n",
       "  'http://localhost:5000/news=714',\n",
       "  '&nbsp&nbsp&nbsp&nbsp大型乳品企业陆续公布的2005年业绩显示,伊利、蒙牛“强者恒强”的格局愈发明朗,而由于“贫富”分化加'],\n",
       " ['文档1738',\n",
       "  'http://localhost:5000/news=1738',\n",
       "  '2006中国营销高峰论坛暨首届中国金麒麟奖颁奖礼金麒麟奖十大新锐营销人物评选活动简介及参评细则2006，中国第一营销专业论坛—中国营销高峰论'],\n",
       " ['文档1228',\n",
       "  'http://localhost:5000/news=1228',\n",
       "  '《经济通记者潘磊华报道》人民银行４月底出其不意将贷款利息上调２７点子，一年期贷款息率从５﹒５８％调高至５﹒８５％，惟存款利率却未有作出调整。'],\n",
       " ['文档1230',\n",
       "  'http://localhost:5000/news=1230',\n",
       "  '《经济通记者潘磊华报道》人民银行４月底出其不意将贷款利息上调２７点子，一年期贷款息率从５﹒５８％调高至５﹒８５％，惟存款利率却未有作出调整。'],\n",
       " ['文档1751',\n",
       "  'http://localhost:5000/news=1751',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司及董事会全体成员保证信息披露内容的真实、准确、完整，没有虚假记载、误导性陈述或重大遗漏。&nb'],\n",
       " ['文档1755',\n",
       "  'http://localhost:5000/news=1755',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司及董事会全体成员保证信息披露内容的真实、准确、完整，没有虚假记载、误导性陈述或重大遗漏。&nb'],\n",
       " ['文档231',\n",
       "  'http://localhost:5000/news=231',\n",
       "  '尽管昨日港股调整迹象明显，但在内地股市昨日涨幅称冠亚洲的激励下，国企指数昨日一度冲至7433.08点，收盘微跌6.91点，收报7364.71'],\n",
       " ['文档1768',\n",
       "  'http://localhost:5000/news=1768',\n",
       "  '2006中国营销高峰论坛暨首届中国金麒麟奖颁奖礼金麒麟奖——十大新锐营销标杆企业评选活动简介及参评细则2006，中国第一营销专业论坛—中国营'],\n",
       " ['文档1259',\n",
       "  'http://localhost:5000/news=1259',\n",
       "  '&nbsp&nbsp&nbsp&nbsp根据德国大众汽车集团最新的数据报告，其2006年第一季度的汽车交货量、销售收入和利润与上年同期相比均'],\n",
       " ['文档1776',\n",
       "  'http://localhost:5000/news=1776',\n",
       "  '近日，中科红旗高调宣布将与日本、韩国公司组建北京亚洲开源技术有限公司（Ａｓｉａｎｕｓ牎Ｔ谒深火热的亚洲市场，三国企业联手能否撼动微软的软件霸'],\n",
       " ['文档753',\n",
       "  'http://localhost:5000/news=753',\n",
       "  '【记者傅春荣9日北京报道】协助目标市场开发减少自主品牌风险记者今天从国家质检总局获悉，为了进一步推动我国汽车产品的出口，减少自主品牌汽车出口'],\n",
       " ['文档1268',\n",
       "  'http://localhost:5000/news=1268',\n",
       "  '&nbsp&nbsp&nbsp&nbsp《经济参考报》报道，汽车产业链一个新的企业战略联盟日前在北京出现。联盟的四方分别是：中国福田汽车(行'],\n",
       " ['文档1269',\n",
       "  'http://localhost:5000/news=1269',\n",
       "  '&nbsp&nbsp&nbsp&nbsp一季度，货车市场仍然保持着5％左右的增长率，连续第二年呈现增速下降的趋势。目前出现的增长仍然是由轻微'],\n",
       " ['文档770',\n",
       "  'http://localhost:5000/news=770',\n",
       "  '工行从高盛“引智”并非意味着对原管理体系全面推倒重来【记者徐思佳9日北京报道】记者日前从工行获悉，自3月16日工行与高盛的战略合作项目正式启'],\n",
       " ['文档1290',\n",
       "  'http://localhost:5000/news=1290',\n",
       "  '水也是资源。在其他资源类商品产品价格一涨再涨，相关上市公司股价叠创新高之际，国内水价提升的强烈预期却没有令水务板块得到应有的重视。水务板块该'],\n",
       " ['文档1291',\n",
       "  'http://localhost:5000/news=1291',\n",
       "  '水也是资源。在其他资源类商品产品价格一涨再涨，相关上市公司股价叠创新高之际，国内水价提升的强烈预期却没有令水务板块得到应有的重视。水务板块该'],\n",
       " ['文档1293',\n",
       "  'http://localhost:5000/news=1293',\n",
       "  '目前，从北京、深圳、广州及上海等地的房地产市场来看，一方面，房价快速上涨，另一方面，各地又有大量的空置楼盘没有出售。特别是一些大城市更是如此'],\n",
       " ['文档1808',\n",
       "  'http://localhost:5000/news=1808',\n",
       "  '&nbsp&nbsp&nbsp&nbsp记者昨天从世界第十一大石化公司———沙特基础工业公司(下称“SABIC”)了解到,该公司将在中国成立'],\n",
       " ['文档1819',\n",
       "  'http://localhost:5000/news=1819',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司及董事会全体成员保证公告内容的真实、准确和完整,对公告的虚假记载、误导性陈述或者重大遗漏负连带'],\n",
       " ['文档285',\n",
       "  'http://localhost:5000/news=285',\n",
       "  '进口棉花贸易规则正式发布本报记者刘文元发自北京8日，中国棉花协会（下称“中棉协”）正式发布实施了中国进口棉花贸易规则——《棉花买卖合同及一般'],\n",
       " ['文档1828',\n",
       "  'http://localhost:5000/news=1828',\n",
       "  '昨日，《第一财经(相关:理财 证券)日报》从信产部官方网站得到消息，信息产业部经商国家发展改革委，批复同意中国移动通信集团公司（下称“中国移'],\n",
       " ['文档810',\n",
       "  'http://localhost:5000/news=810',\n",
       "  '在北京市科学技术奖励大会上，91岁的唐亚伟老人获得一等奖，是获奖者中年龄最大的一位。记者 张越／摄大学生受聘中关村可落户 条件是本市上学的应'],\n",
       " ['文档1835',\n",
       "  'http://localhost:5000/news=1835',\n",
       "  '&nbsp&nbsp&nbsp&nbsp上市公司名称：长沙中联重工科技发展股份有限公司&nbsp&nbsp&nbsp&nbsp股票上市地点：'],\n",
       " ['文档1836',\n",
       "  'http://localhost:5000/news=1836',\n",
       "  '&nbsp&nbsp&nbsp&nbsp上市公司：长沙中联重工科技发展股份有限公司&nbsp&nbsp&nbsp&nbsp上市地点：深圳证券'],\n",
       " ['文档1840',\n",
       "  'http://localhost:5000/news=1840',\n",
       "  '&nbsp&nbsp&nbsp&nbsp面对大陆业务比重的日渐上升,台湾航运巨头长荣集团正在积极开拓大陆市场。昨日,上海证券报从长荣集团获悉'],\n",
       " ['文档1329',\n",
       "  'http://localhost:5000/news=1329',\n",
       "  '&nbsp&nbsp&nbsp&nbsp上市公司名称：银川新华百货商店股份有限公司&nbsp&nbsp&nbsp&nbsp办  公  地  '],\n",
       " ['文档309',\n",
       "  'http://localhost:5000/news=309',\n",
       "  '本报记者刘文元发自北京在经过连续5个交易日的下行之后，昨天国内棉花价格终于出现反弹。国内棉花产区不良的天气状况以及棉花企业库存下降，促成了棉'],\n",
       " ['文档1853',\n",
       "  'http://localhost:5000/news=1853',\n",
       "  '&nbsp&nbsp&nbsp&nbsp本公司及其董事保证信息披露内容的真实、准确、完整，没有虚假记载、误导性陈述或重大遗漏。&nbsp&n'],\n",
       " ['文档831',\n",
       "  'http://localhost:5000/news=831',\n",
       "  '&nbsp&nbsp&nbsp&nbspG太极(行情,论坛)(600129)公司是国内著名的医药企业,,并已发展成为国内医药产业链最为完整的'],\n",
       " ['文档832',\n",
       "  'http://localhost:5000/news=832',\n",
       "  '&nbsp&nbsp&nbsp&nbsp香梨股份(行情,论坛)(600506)是新疆的农业龙头企业,一直享受国家税收减免、财政补贴和民族政策'],\n",
       " ['文档1347',\n",
       "  'http://localhost:5000/news=1347',\n",
       "  '不同年限的月供额      15年      20年     25年      30年    加息前(5.508％)    2452.52 '],\n",
       " ['文档839',\n",
       "  'http://localhost:5000/news=839',\n",
       "  '&nbsp&nbsp&nbsp&nbsp第四届中国国际农产品交易会(下称“农交会”)将于2006年10月16日在北京举办,这是农业部副部长牛'],\n",
       " ['文档840',\n",
       "  'http://localhost:5000/news=840',\n",
       "  '【记者程武9日北京报道】根据韬睿咨询公司最新的全球人力资源管理调研结果，只有8％的中国员工被认为具有高敬业度，并且愿意为所在企业做出更多的贡'],\n",
       " ['文档1866',\n",
       "  'http://localhost:5000/news=1866',\n",
       "  '&nbsp&nbsp&nbsp&nbsp保荐机构：中信证券&nbsp&nbsp&nbsp&nbsp签署时间：二○○六年五月八日&nbsp&n'],\n",
       " ['文档339',\n",
       "  'http://localhost:5000/news=339',\n",
       "  '&nbsp&nbsp&nbsp&nbsp当前的市场可以说是热闹非凡,各种题材都在强势上攻,涨停板比比皆是,市场上演逼空行情。但是很多投资者都'],\n",
       " ['文档1373',\n",
       "  'http://localhost:5000/news=1373',\n",
       "  '“解决争端就像跳舞，得靠双方互动。”欧盟驻华大使安博对《财经(相关:理财 证券)》说□本刊记者 楼夷 实习研究员柯兰如/文“在欧洲，我感受到'],\n",
       " ['文档1384',\n",
       "  'http://localhost:5000/news=1384',\n",
       "  '根据对经济师的一份调查结果显示，由于上升的出口抵消了原油价格攀升的影响，德国工业产出预期将连续第三个月上升。根据对44名经济师的调查结果显示'],\n",
       " ['文档882',\n",
       "  'http://localhost:5000/news=882',\n",
       "  '本报记者刘文元发自北京在经过连续5个交易日的下行之后，昨天国内棉花价格终于出现反弹。国内棉花产区不良的天气状况以及棉花企业库存下降，促成了棉'],\n",
       " ['文档884',\n",
       "  'http://localhost:5000/news=884',\n",
       "  '本报记者刘文元发自北京8日，中国棉花协会（下称“中棉协”）正式发布实施了中国进口棉花贸易规则——《棉花买卖合同及一般条款》（适用于非国产棉贸'],\n",
       " ['文档391',\n",
       "  'http://localhost:5000/news=391',\n",
       "  '&nbsp&nbsp&nbsp&nbsp尊敬的各位股东:&nbsp&nbsp&nbsp&nbsp你们好！&nbsp&nbsp&nbsp&nb'],\n",
       " ['文档906',\n",
       "  'http://localhost:5000/news=906',\n",
       "  '新华网北京５月９日电（记者赵晓辉）中国移动北京地区手机资费调整方案于８日出台，手机资费价格坚冰终被打破。此间专家指出，这种调整应该只是一个开'],\n",
       " ['文档916',\n",
       "  'http://localhost:5000/news=916',\n",
       "  '《经济通专讯》物美商业（８２７７）董事长张文中于业绩记者会表示，目前现金储备充裕，没有银行负债，除非未来有大型收购项目，否则现阶段未有考虑再'],\n",
       " ['文档918',\n",
       "  'http://localhost:5000/news=918',\n",
       "  '新华网北京５月９日电（记者张晓松）为解决偏远地区农民用药问题，国家食品药品监督管理局日前出台《农村偏远地区药柜设置规定（试行）》，允许有配送'],\n",
       " ['文档1455',\n",
       "  'http://localhost:5000/news=1455',\n",
       "  '&nbsp&nbsp&nbsp&nbsp多头能量聚集,大盘保持强势：今天沪深股市延续昨天强势上升的惯性,跳高开盘,沪指在上摸至1509点便受'],\n",
       " ['文档1976',\n",
       "  'http://localhost:5000/news=1976',\n",
       "  '折翅的“东方不死鸟”依托着地缘优势和文化的共融性，借助着中国市场开放的机遇，市场嗅觉灵敏的日本电器企业都已不约而同地选择了登陆中国市场。然而'],\n",
       " ['文档955',\n",
       "  'http://localhost:5000/news=955',\n",
       "  '《神州经脉》内地股市在恢复再融资的压力下不跌反升，深沪综指在「五一」长假后连续第二日上扬，沪综指今日（９日）收市涨２﹒２７％，轻易攻上１５３'],\n",
       " ['文档957',\n",
       "  'http://localhost:5000/news=957',\n",
       "  '《神州经脉》内地股市在恢复再融资的压力下不跌反升，深沪综指在「五一」长假后连续第二日上扬，沪综指今日（９日）收市涨２﹒２７％，轻易攻上１５３'],\n",
       " ['文档479',\n",
       "  'http://localhost:5000/news=479',\n",
       "  '从今年开始，北京的企业在技术研发上投入越多，纳税将会越少。记者从昨日召开的北京市科技大会上获悉，北京企业用于技术开发费用的150%可以抵扣当'],\n",
       " ['文档487',\n",
       "  'http://localhost:5000/news=487',\n",
       "  '&nbsp&nbsp&nbsp&nbsp增发提升估值水平&nbsp&nbsp&nbsp&nbspG中信(行情,论坛)(600030)5月8日'],\n",
       " ['文档1517',\n",
       "  'http://localhost:5000/news=1517',\n",
       "  '本报记者 华观发北京报道尽快恢复和改善资本市场的融资功能已进入制度准备阶段。4月28日，证监会公布了《首次公开发行股票并上市管理办法（征求意']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.056px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
